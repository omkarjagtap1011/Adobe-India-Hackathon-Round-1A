# Adobe "Connecting the Dots" Hackathon Solutions

This repository contains solutions for Adobe's "Connecting the Dots" hackathon challenges focusing on intelligent document processing and analysis.

## ğŸ† Challenge Overview

Adobe's hackathon presents real-world document intelligence problems that require innovative solutions combining PDF processing, natural language understanding, and user-centric design.

## ğŸ“ Project Structure

```
adobe/
â”œâ”€â”€ Challenge_1a/          # PDF Outline Extractor
â”‚   â”œâ”€â”€ main.py           # Core extraction algorithm
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Container configuration
â”‚   â””â”€â”€ README.md         # Challenge-specific documentation
â”‚
â”œâ”€â”€ Challenge_1b/          # Persona-Driven Document Intelligence
â”‚   â”œâ”€â”€ main.py           # Core intelligence algorithm
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Container configuration
â”‚   â””â”€â”€ README.md         # Challenge-specific documentation
â”‚
â”œâ”€â”€ .gitignore            # Git ignore rules
â””â”€â”€ README.md             # This file
```
## ğŸš€ Solutions Summary

### Challenge 1B: Persona-Driven Document Intelligence
- **Purpose**: Intelligent document analysis based on user personas and tasks
- **Technology**: Python 3.9, PyMuPDF, Advanced NLP techniques
- **Features**: Relevance scoring, section prioritization, multi-document processing
- **Performance**: Scalable algorithm with contextual understanding

## ğŸ§  Approach

This solution performs intelligent section retrieval based on a user persona and task using offline NLP and vector search.

### ğŸ” Pipeline Overview

#### ğŸ“„ PDF Section Extraction  
PDFs are parsed using **PyMuPDF** to extract sections and corresponding text, saved in structured **JSON**.

#### âœ‚ï¸ Text Chunking  
Long sections are split into smaller, coherent **chunks** for improved embedding and search accuracy.

#### ğŸ§  Embedding & Vector DB Storage  
Chunks are embedded using a lightweight offline model and stored in **ChromaDB** for fast **semantic search**.

#### ğŸ” Semantic Retrieval  
**Persona + task** query is embedded and used to retrieve **top 10 relevant chunks** from ChromaDB.

#### ğŸ§  Reranking with Nomic  
Retrieved chunks are **reranked using the `nomic-embed-text` model** for better alignment with persona intent.

#### ğŸ§¾ Final Output Formatting  
Top 5 sections are selected and returned in **structured JSON** format as per challenge requirements.

## ğŸ› ï¸ Technical Stack

| Component         | Tool / Library                | Purpose                                               |
|------------------|-------------------------------|-------------------------------------------------------|
| Language          | Python 3.10                    | Core programming language                             |
| PDF Parsing       | PyMuPDF (`fitz`)               | Extracts section-wise text from PDFs                 |
| Structuring Logic | `extract_struct.py`            | Identifies section headers and chunks content         |
| Embeddings        | `nomic-embed-text` (via Ollama)| Generates semantic vectors and reranking embeddings   |
| Vector Store      | ChromaDB                       | Stores and queries vectors using cosine similarity    |
| Reranking Model   | CrossEncoder (MiniLM)          | Reranks top sections based on persona/task relevance  |
| LLM Access (opt.) | TinyLLaMA via `llama-cpp-python` | Local model loading via HuggingFace (optional)       |
| Embedding Server  | Ollama                         | Serves embedding models via local API                |
| Data Format       | JSON                           | For structured input and output                      |
| Containerization  | Docker (AMD64)                 | Optional for reproducible, isolated execution         |


   













