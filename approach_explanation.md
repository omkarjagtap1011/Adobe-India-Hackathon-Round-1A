# Adobe "Connecting the Dots" Hackathon Solutions

This repository contains solutions for Adobe's "Connecting the Dots" hackathon challenges focusing on intelligent document processing and analysis.

## ğŸ† Challenge Overview

Adobe's hackathon presents real-world document intelligence problems that require innovative solutions combining PDF processing, natural language understanding, and user-centric design.

## ğŸ“ Project Structure

```
adobe/
â”œâ”€â”€ Challenge_1a/          # PDF Outline Extractor
â”‚   â”œâ”€â”€ main.py           # Core extraction algorithm
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Container configuration
â”‚   â””â”€â”€ README.md         # Challenge-specific documentation
â”‚
â”œâ”€â”€ Challenge_1b/          # Persona-Driven Document Intelligence
â”‚   â”œâ”€â”€ main.py           # Core intelligence algorithm
â”‚   â”œâ”€â”€ requirements.txt  # Dependencies
â”‚   â”œâ”€â”€ Dockerfile        # Container configuration
â”‚   â””â”€â”€ README.md         # Challenge-specific documentation
â”‚
â”œâ”€â”€ .gitignore            # Git ignore rules
â””â”€â”€ README.md             # This file
```
## ğŸš€ Solutions Summary

### Challenge 1B: Persona-Driven Document Intelligence
- **Purpose**: Intelligent document analysis based on user personas and tasks
- **Technology**: Python 3.9, PyMuPDF, Advanced NLP techniques
- **Features**: Relevance scoring, section prioritization, multi-document processing
- **Performance**: Scalable algorithm with contextual understanding

---

## ğŸ§  Approach

Our system identifies and returns the most relevant sections of a PDF tailored to a persona's intent by combining:

â€¢â   â Text-based PDF parsing
â€¢â   â Lightweight offline embedding
â€¢â   â Vector similarity search
â€¢â   â Persona-aware reranking

---

## ğŸ” Pipeline Overview

1.â  â *PDF Section Extraction*  
   â†’ Parse PDFs with *PyMuPDF* into structured sections saved as JSON.

2.â  â *Text Chunking*  
   â†’ Split long sections into *smaller coherent chunks* for better semantic representation.

3.â  â *Embedding & Storage*  
   â†’ Embed each chunk using a *lightweight offline model. Store in **ChromaDB* for fast vector search.

4.â  â *Semantic Querying*  
   â†’ Embed the combined *persona + task query* and retrieve *top 10 relevant chunks* from ChromaDB.

5.â  â *Reranking with Nomic*  
   â†’ Refine relevance using the *nomic-embed-text* model for *intent-aware ranking*.

6.â  â *Output Formatting*  
   â†’ Return *top 5 matched sections* in a structured â â€¯output.jsonâ€¯â .


## ğŸ› ï¸ Technical Stack

| Component         | Tool / Library                | Purpose                                               |
|------------------|-------------------------------|-------------------------------------------------------|
| Language          | Python 3.10                    | Core programming language                             |
| PDF Parsing       | PyMuPDF (`fitz`)               | Extracts section-wise text from PDFs                 |
| Structuring Logic | `extract_struct.py`            | Identifies section headers and chunks content         |
| Embeddings        | `nomic-embed-text` (via Ollama)| Generates semantic vectors and reranking embeddings   |
| Vector Store      | ChromaDB                       | Stores and queries vectors using cosine similarity    |
| Reranking Model   | CrossEncoder (MiniLM)          | Reranks top sections based on persona/task relevance  |
| LLM Access (opt.) | TinyLLaMA via `llama-cpp-python` | Local model loading via HuggingFace (optional)       |
| Embedding Server  | Ollama                         | Serves embedding models via local API                |
| Data Format       | JSON                           | For structured input and output                      |
| Containerization  | Docker (AMD64)                 | Optional for reproducible, isolated execution         |


   













